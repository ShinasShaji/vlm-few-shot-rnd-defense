\section{Conclusions}
% \subsection{Key Findings}
\begin{frame}{Key Findings}
\framesubtitle{What did we learn about VLM few-shot transfer?}
  \vspace{-0.4em}
  \begin{columns}[T]
    \column{\customcolumnwidth}
      \textbf{General Domain (CIFAR-10)}
      \vspace{-0.2em}
      \begin{itemize}
        \item VLMs show \emph{fairly good transfer} to this task
        \item Downstream models achieve near ground-truth performance
        \begin{itemize}
          \item Only 5\% below models trained from ground-truth
          \item \emph{Resilient} to pseudolabel noise
          % \item Outperform VLMs in most cases
        \end{itemize}
      \end{itemize}
    \column{\customcolumnwidth}
      \textbf{Specialized Domain (Derm7Pt)}
      \vspace{-0.2em}
      \begin{itemize}
        \item \emph{Limited transfer} to specialized domains (Derm7Pt)
        \begin{itemize}
          \item Performance near random-guessing
          \item Suggests \emph{strong reliance} on pre-trained knowledge
        \end{itemize}
        \item Multi-modal \emph{integration challenges} exist
      \end{itemize}
  \end{columns}
  % \vspace{0.2em}
  \textbf{We find:}
  \begin{itemize}
    \item Zero / low-shot approaches with \emph{simple prompting} most effective
    \item Simpler prompting strategies generally outperform complex ones
    \item Examples help model \emph{recognize} the task (from pre-trained priors)~\footfullciteieee{Pan2023}
  \end{itemize}
  \vspace{-0.4em}
  \blfootnote{\vspace{0.05em}}
\end{frame}
\note{
- Zero-shot and low-shot approaches with simple prompting proved most effective for general domain tasks \\
- However, performance degraded significantly on specialized medical tasks (Derm7Pt). The domain is likely underrepresented in the pre-training data of the VLMs \\
- Architecture choices significantly impacted both performance and resource efficiency, e.g. the Perceiver-resampler architecture used in one of our models performs quite well, accuracy, memory, and time-wise \\
- Additional shots or reasoning requirements often increased costs without proportional gains \\
- Results suggest focusing on activating existing capabilities and knowledge rather than teaching new ones \\
- Each kind of image is a different modality in the dermatology case. The model may not know how to look at both image which are two forms of the same thing, and reason and understand the relationship between the two. The integration of the two modalities is a challenge. How do you look at to forms of the same thing and reason about the relationship between the two? \\
}


\begin{frame}{Key Contributions}
\framesubtitle{How did we help?}
  \vspace{-1em}
  \begin{itemize}
    \item Advancing the understanding of \emph{few-shot transfer} of VLMs:
    \begin{itemize}
      \item providing a comprehensive \emph{evaluation framework} for assessing VLM transfer
      \item providing \emph{practical guidelines} for their transfer to dataset annotation tasks to train task-specific downstream models
    \end{itemize}
    \item Empirical findings suggest downstream models are \emph{resilient to label noise}:
    \begin{itemize}
      \item significant for deploying these systems in \emph{resource-constrained} environments
      \item suggests that VLMs \emph{can} support the learning of smaller, task-specific models despite imperfect predictions
    \end{itemize}
  \end{itemize}
\end{frame}
\note{}


% \subsection{Limitations and Future Work}
\begin{frame}{Limitations and Future Work}
\framesubtitle{What constrained us, and what could be worked upon?}
  \vspace{-1em}
  \begin{columns}[T]
    \column{\customcolumnwidth}
      \textbf{Technical Limitations}
      \begin{itemize}
        \item Context length and memory constraints
        \item Limited / \emph{degraded performance scaling} with number of examples
        \item \emph{Limited generalization} to specialized domains
      \end{itemize}
      \textbf{General Limitations}
      \begin{itemize}
        \item Limited selection of models, datasets, tasks
        \item Findings of this work may not generalize to all vision tasks
      \end{itemize}
      \column{\customcolumnwidth}
      \textbf{Future Research Directions}
      \begin{itemize}
        \item Generalizable \emph{domain-transferable} pre-training strategies
        \item More \emph{efficient} VLM architectures for multi-image processing
        \item Improving prompting strategies and \emph{visual grounding}~\footfullciteieee{Yang2023}
        \item Extending investigation to \emph{other vision tasks}
      \end{itemize}
  \end{columns}
\end{frame}
\note{
- Context length and memory limitations restricted few-shot experiments to limited examples and constrained larger models, and high resolution images had to be rescaled to fit more examples \\
- Poor performance on specialized domains suggests models rely more on pre-trained priors than learning new capabilities \\
- There are some things that you can tell beforehand are bad ideas, and this was not specifically one of them. We expected before starting the project that more examples would strictly improve performance, but this was not the case. In NLP and LLMs, few-shot transfer and chain-of-thought prompting is extremely effective, but this is not the case for vision-language models and vision-language tasks, as we see here. \\
- More efficient VLM architectures needed for scalable high-resolution multi-image processing. Not only this, but for the use of VLMs and VLAs in robots in general, the ability to process multiple images at once and keep them in context is extremely important. \\
- Other vision tasks to try: object detection, segmentation, captioning to support a contrastive learner, etc.
}


% \section{Q\&A}
\begin{frame}{Thank You!}
  \vspace{6em}
  \centering
  \vfill
  {\LARGE \textbf{Questions?}}
  \vfill
  \vspace{6em}
  \raggedright\textbf{Contact:}
  \begin{itemize}
    \item shinas.shaji@smail.inf.h-brs.de
    \item shinas.shaji@iais.fraunhofer.de
  \end{itemize}
  \vfill
\end{frame}
\note{
Q: Why were advanced models such as GPT-4o and other closed-source models not used in the work? \\
A: Multiple reasons: \\
- compute analysis cannot be performed, as memory usage cannot be read, times are dependent on network, and the size of the model is unknown \\
- we focus on open-source models, for whom the architectural details are known. This enables us to see, for example, that the perciever-resampler architecture used in one of our models performs quite well, accuracy, memory, and time-wise \\
- we cannot be sure that our datasets are in the dataset training mix for closed-source models. Open-source work typically also mentions the training data mix and datasets used. Remember, we needed to check how few-shot learning performs when we know that similar tasks are not in the pre-training data for the model \\
- closed-source models can get quite expensive when we need to push a whole dataset through them. We can however use batched inferences for half the cost. However, the code and processing would require overhauls to support this, and this was perhaps beyond scope
}